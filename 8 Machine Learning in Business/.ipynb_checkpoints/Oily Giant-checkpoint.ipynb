{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Business project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You work for the OilyGiant mining company. Your task is to find the best place for a new well.\n",
    "\n",
    "**Steps to choose the location:**\n",
    "1. Collect the oil well parameters in the selected region: oil quality and volume of reserves;\n",
    "2. Build a model for predicting the volume of reserves in the new wells;\n",
    "3. Pick the oil wells with the highest estimated values;\n",
    "4. Pick the region with the highest total profit for the selected oil wells.\n",
    "\n",
    "You have data on oil samples from three regions. \n",
    "Parameters of each oil well\n",
    "in the region are already known. Build a model that will help to pick the region\n",
    "with the highest profit margin. Analyze potential profit and risks using the\n",
    "Bootstrap technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only linear regression is suitable for model training (the rest are not sufficiently predictable).\n",
    "\n",
    "When exploring the region, a study of 500 points is carried with picking the best 200 points for the profit calculation.\n",
    "\n",
    "The budget for oil well development is 100 USD million.\n",
    "\n",
    "One barrel of raw materials brings 4.5 USD of revenue The revenue from one unit of product is 4,500 dollars (volume of reserves is in thousand barrels).\n",
    "\n",
    "After the risk evaluation, keep only the regions with the risk of losses lower than 2.5%. From the ones that fit the criteria, the region with the highest average profit should be selected.\n",
    "\n",
    "The data is synthetic: contract details and well characteristics are not disclosed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Download and prepare the data. Explain the procedure.**\n",
    "\n",
    "2. **Train and test the model for each region:**\n",
    "\n",
    "    2.1. Split the data into a training set and validation set at a ratio of 75:25.\n",
    "    \n",
    "    2.2. Train the model and make predictions for the validation set.\n",
    "    \n",
    "    2.3. Save the predictions and correct answers for the validation set.\n",
    "    \n",
    "    2.4. Print the average volume of predicted reserves and model RMSE.\n",
    "    \n",
    "    2.5. Analyze the results.\n",
    "\n",
    "3. **Prepare for profit calculation:**\n",
    "    \n",
    "    3.1. Store all key values for calculations in separate variables.\n",
    "    \n",
    "    3.2. Calculate the volume of reserves sufficient for developing a new well without losses. Compare the obtained   value with the average volume of reserves in each region.\n",
    "    \n",
    "    3.3. Provide the findings about the preparation for profit calculation step.\n",
    "\n",
    "4. **Write a function to calculate profit from a set of selected oil wells and model predictions:**\n",
    "    \n",
    "    4.1. Pick the wells with the highest values of predictions. The number of wells depends on the budget and cost of developing one oil well.\n",
    "    \n",
    "    4.2. Summarize the target volume of reserves in accordance with these predictions\n",
    "    \n",
    "    4.3. Provide findings: suggest a region for oil wells' development and\n",
    "    justify the choice. Calculate the profit for the obtained volume of reserves.\n",
    "\n",
    "5. **Calculate risks and profit for each region:**\n",
    "    \n",
    "    5.1. Use the bootstrap technique with 1000 samples to find the distribution of profit.\n",
    "    \n",
    "    5.2. Find average profit, 95% confidence interval and risk of losses. Loss is negative profit.\n",
    "    \n",
    "    5.3. Provide findings: suggest a region for development of oil wells and justify the choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading  and preparing the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Data_0 info--------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      "id         100000 non-null object\n",
      "f0         100000 non-null float64\n",
      "f1         100000 non-null float64\n",
      "f2         100000 non-null float64\n",
      "product    100000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "-------------------Data_1 info--------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      "id         100000 non-null object\n",
      "f0         100000 non-null float64\n",
      "f1         100000 non-null float64\n",
      "f2         100000 non-null float64\n",
      "product    100000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "-------------------Data_2 info--------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      "id         100000 non-null object\n",
      "f0         100000 non-null float64\n",
      "f1         100000 non-null float64\n",
      "f2         100000 non-null float64\n",
      "product    100000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Exploring data and getting info about it\n",
    "data_0 = pd.read_csv('/datasets/geo_data_0.csv')\n",
    "data_1 = pd.read_csv('/datasets/geo_data_1.csv')\n",
    "data_2 = pd.read_csv('/datasets/geo_data_2.csv')\n",
    "print(\"-------------------Data_0 info--------------------\")\n",
    "print(data_0.info())\n",
    "print(\"-------------------Data_1 info--------------------\")\n",
    "print(data_1.info())\n",
    "print(\"-------------------Data_2 info--------------------\")\n",
    "print(data_2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(data):\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------data_0 first five rows--------------------\n",
      "      id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
      "-------------------data_1 first five rows--------------------\n",
      "      id         f0         f1        f2     product\n",
      "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n",
      "-------------------data_2 first five rows--------------------\n",
      "      id        f0        f1        f2     product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n"
     ]
    }
   ],
   "source": [
    "#Printing datas' first 5 rows\n",
    "print('-------------------data_0 first five rows--------------------')\n",
    "print_data(data_0)\n",
    "print('-------------------data_1 first five rows--------------------')\n",
    "print_data(data_1)\n",
    "print('-------------------data_2 first five rows--------------------')\n",
    "print_data(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows in data_0: 0\n",
      "Duplicated rows in data_1: 0\n",
      "Duplicated rows in data_2: 0\n"
     ]
    }
   ],
   "source": [
    "#Checking data for duplicated rows\n",
    "### NOTE wi didnot check data for missing values because when we have used info() method there were not missing values\n",
    "print(\"Duplicated rows in data_0:\", data_0.duplicated().sum())\n",
    "print(\"Duplicated rows in data_1:\", data_1.duplicated().sum())\n",
    "print(\"Duplicated rows in data_2:\", data_2.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will drop id column because it will make unrelated relations \n",
    "def id_drop(data):\n",
    "    data = data.drop('id',axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f0        f1        f2     product\n",
      "0  0.705745 -0.497823  1.221170  105.280062\n",
      "1  1.334711 -0.340164  4.365080   73.037750\n",
      "2  1.022732  0.151990  1.419926   85.265647\n",
      "3 -0.032172  0.139033  2.978566  168.620776\n",
      "4  1.988431  0.155413  4.751769  154.036647\n",
      "          f0         f1        f2     product\n",
      "0 -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  14.272088  -3.475083  0.999183   26.953261\n",
      "2   6.263187  -5.948386  5.001160  134.766305\n",
      "3 -13.081196 -11.506057  4.999415  137.945408\n",
      "4  12.702195  -8.147433  5.004363  134.766305\n",
      "         f0        f1        f2     product\n",
      "0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  0.262778  0.269839 -2.530187   56.069697\n",
      "2  0.194587  0.289035 -5.586433   62.871910\n",
      "3  2.236060 -0.553760  0.930038  114.572842\n",
      "4 -0.515993  1.716266  5.899011  149.600746\n"
     ]
    }
   ],
   "source": [
    "data_0 = id_drop(data_0)\n",
    "data_1 = id_drop(data_1)\n",
    "data_2 = id_drop(data_2)\n",
    "print_data(data_0)\n",
    "print_data(data_1)\n",
    "print_data(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we have read data from csv file. Then we got general info about it then we printed first rows. After that checked for duplicates and dropped `id` column for saving model to make unrelated relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Train and test the model for each region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitter function will split data into train and validation sets\n",
    "def splitter(data):\n",
    "    target = data['product']\n",
    "    features = data.drop('product', axis = 1)\n",
    "    \n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size = 0.25, random_state = 12345)\n",
    "    \n",
    "    return features_train, features_valid, target_train, target_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_0, features_valid_0, target_train_0, target_valid_0 = splitter(data_0)\n",
    "features_train_1, features_valid_1, target_train_1, target_valid_1 = splitter(data_1)\n",
    "features_train_2, features_valid_2, target_train_2, target_valid_2 = splitter(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer function will train data and the will predict by using validation set for getting RMSE\n",
    "def trainer(features_train, features_valid, target_train, target_valid):\n",
    "    model = LinearRegression()\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    \n",
    "    avg = predicted_valid.mean()\n",
    "    \n",
    "    mse = mean_squared_error(target_valid, predicted_valid)\n",
    "    rmse = mse ** 0.5\n",
    "    \n",
    "    return avg, rmse, predicted_valid\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Average volume for data_0 = 92.59 and rmse = 37.58\n",
      "Predicted Average volume for data_1 = 68.73 and rmse = 0.89\n",
      "Predicted Average volume for data_2 = 94.97 and rmse = 40.03\n"
     ]
    }
   ],
   "source": [
    "avg_0, rmse_0, predicted_valid_0 = trainer(features_train_0, features_valid_0, target_train_0, target_valid_0)\n",
    "avg_1, rmse_1, predicted_valid_1 = trainer(features_train_1, features_valid_1, target_train_1, target_valid_1)\n",
    "avg_2, rmse_2, predicted_valid_2 = trainer(features_train_2, features_valid_2, target_train_2, target_valid_2)\n",
    "\n",
    "print(\"Predicted Average volume for data_0 = {:.2f} and rmse = {:.2f}\".format(avg_0, rmse_0))\n",
    "print(\"Predicted Average volume for data_1 = {:.2f} and rmse = {:.2f}\".format(avg_1, rmse_1))\n",
    "print(\"Predicted Average volume for data_2 = {:.2f} and rmse = {:.2f}\".format(avg_2, rmse_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.DataFrame({'Actual': target_valid_0, 'Predicted': predicted_valid_0}).reset_index(drop=True)\n",
    "df_1 = pd.DataFrame({'Actual': target_valid_1, 'Predicted': predicted_valid_1}).reset_index(drop=True)\n",
    "df_2 = pd.DataFrame({'Actual': target_valid_2, 'Predicted': predicted_valid_2}).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have splitted our data by using `splitter` function. Then trained our data with `trainer` function. After that we added predicted volume and actual volume into one dataframe for further usings. From the results of training we can easily see that 1st geolocation average volume less than others and this is related also  to rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare for profit calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The volume of reserves sufficient for developing a new well without losses = 111.1\n"
     ]
    }
   ],
   "source": [
    "budget = 100000000\n",
    "num_of_wells = 200\n",
    "revenue = 4500 # to 1000 barrels\n",
    "volume =  (budget / num_of_wells) / revenue\n",
    "print('The volume of reserves sufficient for developing a new well without losses = {:.1f}'.format(volume))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have calculated volume of reserves sufficient for developing a new well without losses, buy using numbers from condition. And get `111.1` as a result. This result differs from previous average result that we found. But if we will take into account rmse 1st geolocations average will be also less in this case "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a function to calculate profit from a set of selected oil wells and model predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will calculate profit\n",
    "def calculate_profit(actual, predicted):\n",
    "    predicted = predicted.sort_values(ascending=False)\n",
    "    highestVolumeWells = actual[predicted.index][:200]\n",
    "    volume = highestVolumeWells.sum()\n",
    "    profit = (revenue * volume) - budget\n",
    "    \n",
    "    return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average profit in 0 region is 33208260.4\n",
      "The average profit in 1 region is 24150867.0\n",
      "The average profit in 2 region is 27103499.6\n"
     ]
    }
   ],
   "source": [
    "print('The average profit in {} region is {:.1f}'.format(0,calculate_profit(df_0['Actual'], df_0['Predicted'])))\n",
    "print('The average profit in {} region is {:.1f}'.format(1,calculate_profit(df_1['Actual'], df_1['Predicted'])))\n",
    "print('The average profit in {} region is {:.1f}'.format(2,calculate_profit(df_2['Actual'], df_2['Predicted'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have calculated profit for each region. And we had took 200 wells from each region which had a highest predicted volumes. As wee see 0 region has a highest profit more than `33` million dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate risks and profit for each region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting random state\n",
    "state = np.random.RandomState(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By this function we will apply bootstrapping\n",
    "def profit_distribution(target,predicted, region):\n",
    "    values = []\n",
    "    negative_count = 0\n",
    "    for i in range(1000):\n",
    "    \n",
    "        target_subsample = target.sample(n=500, replace=True, random_state = state)\n",
    "        predicted_subsample = predicted[target_subsample.index][:len(target)]\n",
    "        profit = calculate_profit(target_subsample, predicted_subsample)\n",
    "        values.append(profit)\n",
    "        if profit < 0 :\n",
    "            negative_count += 1\n",
    "            \n",
    "\n",
    "    values = pd.Series(values)\n",
    "    lower = values.quantile(.025)\n",
    "    upper = values.quantile(.975)\n",
    "    loss_probability = negative_count / len(values)\n",
    "    \n",
    "    mean = values.mean()\n",
    "    print(\"Average profit for region {} is: {:.3f}\".format(region, mean))\n",
    "    print(\"Confidence interval for region {} is between {:.3f} and {:.3f}\".format(region, lower, upper))\n",
    "    print(\"The probability loss is {:.2%}\".format(loss_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average profit for region 0 is: 4259385.269\n",
      "Confidence interval for region 0 is between -1020900.948 and 9479763.534\n",
      "The probability loss is 6.00%\n",
      "Average profit for region 1 is: 5182594.937\n",
      "Confidence interval for region 1 is between 1281232.314 and 9536129.821\n",
      "The probability loss is 0.30%\n",
      "Average profit for region 2 is: 4201940.053\n",
      "Confidence interval for region 2 is between -1158526.092 and 9896299.398\n",
      "The probability loss is 6.20%\n"
     ]
    }
   ],
   "source": [
    "profit_distribution(df_0['Actual'], df_0['Predicted'], 0)\n",
    "profit_distribution(df_1['Actual'], df_1['Predicted'], 1)\n",
    "profit_distribution(df_2['Actual'], df_2['Predicted'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have applied Boostrapping with `1000` samples. For 0 and 2 regions we got negative values which is meaning loss. As wee see we have minimum risk at region 1.And also it's average profit bigger than others. And region 1 profit distrubition falls into positive values. So it is better choosing this region 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made lots of things. Opened data and explored it. Then splitted it into train and test sets, then trained it. After that we calculated lossless volume well. Then we calculated profit for each region. Then we have applied bootstrapping technoligie. According to our findings region 1 has less risk than others and highest average profit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
